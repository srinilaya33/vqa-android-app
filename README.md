## Visual Question Answering Android App

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Android](https://img.shields.io/badge/Android-Kotlin-green.svg)
![AI](https://img.shields.io/badge/AI-Transformers-orange.svg)
![FastAPI](https://img.shields.io/badge/Backend-FastAPI-teal.svg)

**An intelligent Android app that answers questions about images using AI**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Setup](#-quick-setup)

</div>

## Features

- **Camera Integration** â€“ Capture images directly from the app  
- **AI-Powered Answers** â€“ Uses ViLT transformer model for VQA  
- **Voice Input Ready** â€“ Architecture prepared for speech recognition  
- **Real-time Processing** â€“ FastAPI backend with async support  
- **Native Android** â€“ Built with Kotlin and modern Android SDK  

## Architecture

```

Android App (Kotlin) â†’ FastAPI Backend â†’ ViLT Model â†’ JSON Response
â†“
Camera Capture â†’ Image Processing â†’ Question â†’ AI Answer

````

## Prerequisites

- Python **3.8+**  
- Android Studio  
- OnePlus Nord 5G (or any Android device)  
- Wi-Fi network  


## Quick Setup

### ğŸ”¹ Backend Setup

```bash
cd backend
pip install -r requirements.txt
python main.py
````

### ğŸ”¹ Android Setup

1. Open `android_app` in **Android Studio**
2. Build and run on a connected Android device
3. Update the IP address in `MainActivity.kt` with your **computerâ€™s IP**


## Technical Stack

### Backend

* **FastAPI** â€“ Modern Python web framework
* **PyTorch** â€“ Deep learning framework
* **Transformers** â€“ Hugging Face AI models
* **ViLT** â€“ Vision-and-Language Transformer model

### Android

* **Kotlin** â€“ Official Android language
* **CameraX** â€“ Modern camera API
* **HTTPURLConnection** â€“ Network requests
* **Material Design** â€“ Modern UI components


## Usage

1. Launch the **Android app**
2. Capture an image using the camera
3. Enter your question about the image
4. Get an instant AI-powered answer

## Example Questions

* â€œWhat color is the object?â€
* â€œIs there a person in the image?â€
* â€œHow many objects are there?â€


## API Endpoints

### **POST** `/answer`

#### Request

```json
{
  "image": "File (JPEG/PNG)",
  "question": "What is in this image?"
}
```

#### Response

```json
{
  "answer": "a cat",
  "status": "success",
  "question": "What is in this image?"
}
```

## Model Performance

| Metric       | Details                         |
| ------------ | ------------------------------- |
| **Model**    | dandelin/vilt-b32-finetuned-vqa |
| **Training** | Fine-tuned on VQAv2 dataset     |
| **Accuracy** | ~70% on VQAv2 validation        |
| **Speed**    | ~1â€“2 seconds per inference      |


## Future Enhancements

* Voice question input
* Multiple image support
* Answer confidence scores
* Offline mode capability
* Image gallery integration


<div align="center">
    
</div>
